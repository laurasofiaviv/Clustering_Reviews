
# An√°lisis de Cl√∫ster de Rese√±as de Clientes de Amazon

## Descripci√≥n del Proyecto

Este proyecto aplica **clustering (agrupaci√≥n)** usando **Machine Learning no supervisado** para identificar segmentos de usuarios seg√∫n su comportamiento de rese√±as en Amazon.

Usamos t√©cnicas de **PySpark** para procesar grandes vol√∫menes de datos de rese√±as, generamos perfiles de usuarios y aplicamos **K-Means** para segmentarlos en grupos significativos. Adem√°s visualizamos los resultados con gr√°ficos y reducci√≥n de dimensi√≥n usando PCA.

---

## üìÇ Dataset

El dataset utilizado se puede descargar desde **Kaggle**:

üëâ https://www.kaggle.com/datasets/vivekprajapati2048/amazon-customer-reviews

Este dataset contiene rese√±as de clientes de Amazon con informaci√≥n como:

- `CustomerID`
- `Score` (calificaci√≥n)
- `HelpfulnessNumerator` (votos √∫tiles)
- `HelpfulnessDenominator` (total de votos)
- Texto de rese√±a
- Otras variables descriptivas

---

## üì• C√≥mo descargar el dataset

1. Visita el siguiente enlace:
   
   https://www.kaggle.com/datasets/vivekprajapati2048/amazon-customer-reviews

2. Inicia sesi√≥n en Kaggle (si no tienes cuenta, reg√≠strate).

3. Descarga el archivo comprimido.

4. Descomprime el archivo y localiza el archivo `.csv` para usarlo en el proyecto.

---

## üìÅ Estructura del proyecto

amazon-review-clustering/

‚îÇ

‚îú‚îÄ‚îÄ analisis_clustering.ipynb       ‚Üê Notebook principal con el c√≥digo

‚îú‚îÄ‚îÄ dataset.csv                     ‚Üê Archivo CSV con los datos (no incluido por tama√±o)

‚îú‚îÄ‚îÄ README.md                       ‚Üê Archivo de documentaci√≥n (este)

‚îî‚îÄ‚îÄ requirements.txt                

---

## Tecnolog√≠as utilizadas

Este proyecto fue desarrollado con:

- **Python**
- **PySpark** (procesamiento distribuido)
- **Pandas** (conversi√≥n para visualizaciones)
- **Matplotlib** (gr√°ficos)
- **Seaborn** (visualizaciones estad√≠sticas)
- **NumPy**
- **Jupyter Notebook / Databricks**

---

## C√≥mo ejecutar el notebook

### Paso 1: Preparar el entorno

Si vas a trabajar de forma local:

1. Aseg√∫rate de tener Python instalado.
2. Instala las bibliotecas necesarias con requirements.txt:

```bash
pip install -r requirements.txt
```
co con:

```bash
pip install pyspark pandas numpy matplotlib seaborn
```

Si usas Databricks, no necesitas instalar nada adicional.

### Paso 2: Colocar el dataset

Despu√©s de descargar y descomprimir el dataset:
	1.	Ubica el archivo .csv dentro de tu carpeta del proyecto.
	2.	Aseg√∫rate de que est√© accesible desde el notebook, por ejemplo:

amazon-review-clustering/dataset.csv



### Paso 3: Abrir y ejecutar el Notebook
	1.	Abre el archivo analisis_clustering.ipynb.
	2.	Ejecuta las celdas en orden desde arriba hacia abajo.
	3.	Verifica que al cargar el dataset no haya errores de ruta.
	4.	Contin√∫a con la preparaci√≥n de datos, clustering y visualizaciones.


## Metodolog√≠a

El an√°lisis sigue estos pasos principales:
	1.	Carga y exploraci√≥n del dataset
	2.	Feature engineering ‚Äî agregaci√≥n por usuario
	3.	Escalamiento de variables usando StandardScaler
	4.	Aplicaci√≥n de K-Means clustering
	5.	Resumen estad√≠stico por cluster
	6.	Visualizaci√≥n de resultados
	‚Ä¢	Gr√°fica de barras
	‚Ä¢	Boxplot de distribuci√≥n
	‚Ä¢	PCA para visualizaci√≥n 2D

---
## Resultados

El an√°lisis gener√≥:
	‚Ä¢	Segmentos de usuarios con comportamientos distintos.
	‚Ä¢	Perfiles de clientes seg√∫n actividad y satisfacci√≥n.
	‚Ä¢	Gr√°ficas que permiten visualizar y comparar clusters.
	‚Ä¢	Reducci√≥n de dimensionalidad para representaci√≥n 2D.


## Interpretaci√≥n de los resultados

Los clusters identificados muestran segmentos diferenciados de usuarios:
	‚Ä¢	Usuarios m√°s activos
	‚Ä¢	Usuarios cr√≠ticos
	‚Ä¢	Usuarios altamente satisfechos
	‚Ä¢	Usuarios con alto impacto en votos √∫tiles

Estos segmentos tienen aplicaci√≥n pr√°ctica en:
	‚Ä¢	Estrategias de marketing
	‚Ä¢	Sistemas de recomendaci√≥n
	‚Ä¢	Mejora de experiencia del cliente


---

## üìå Notas importantes
	‚Ä¢	El dataset no est√° incluido por restricciones de tama√±o.
	‚Ä¢	Para grandes vol√∫menes es preferible ejecutar el notebook en entornos como Databricks o Google Colab.
	‚Ä¢	Aseg√∫rate de tener suficiente memoria si trabajas localmente.



Proyecto de Clustering para an√°lisis de comportamiento en grandes vol√∫menes de datos

---
